---
title: "Basic GLM"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
One-Way analysis is definitely good and useful, but there can sometimes be certain problems:
- There could be correlation between variables used in one-way analysis.
- How do you determine which variables are best used to describe / predict target?
- How do you quantify the independent influence of correlated variables on target?

This is where Multi-Way approach comes in. Multi-Way analysis is usually done using a statistical or machine learning model. In insurance, when we want to create a very transparent and easily interpretable model, we usually used Generalized Linear Models - GLM.

GLM is a generalization of well-known linear regression, which can be used for statistical inference when the target or error distribution is not Gaussian. Some insurance events, like frequency of claims or their payments have been highly studied and associated with some empirical distributions:
- Frequency of claims (claim count / exposure) does approximately follow Poisson distribution.
- Severity of claims (claim loss / claim count) does approximately follow Gamma distribution.
- Burning cost (claim loss / exposure) does approximately follow Tweedie distribution.

You can read more about GLM in the wikipedia article:
https://en.wikipedia.org/wiki/Generalized_linear_model

Since we are using Burning cost (riskiness per unit of exposure) our target will roughly follow Tweedie distribution (a lot of zeros and then skewed with long tail).
If you are interested, you can read more in the wikipedia article:
https://en.wikipedia.org/wiki/Tweedie_distribution

Tweedie distribution is a generalization and compound of multiple different distributions. This is controlled with the Tweedie 'power parameter' or 'p'. If p > 1 and p < 2 then the distribution is a compound of Poisson and Gamma and therefore suitable to model the Burning Cost target. Let's use p=1.5 as a good default parameter.

```{r}
# install.packages(c("statmod", "tweedie"))
library(statmod)
library(tweedie)
library(dplyr)

dt_pol_w_claims <- readRDS("./Data/dt_pol_w_claims_target.rds") %>%
  mutate(Time_Exposure = as.integer(Time_Exposure)) %>%
  filter(!(is.na(Veh_type2) | Veh_type2 == ""))
```

Let's fit a basic GLM using a single variable - Veh_type2. This will get results very similar to the one-way analysis.

```{r}
basic_model <- glm(
  data = dt_pol_w_claims,
  formula = Burning_Cost ~ Veh_type2,
  family = statmod::tweedie(var.power = 1.5, link.power = 0),
  weights = Time_Exposure
)

summary(basic_model)
```
The most basic information we want to get from the model are the coefficients. Since vehicle type is a categorical variable, each of its category is fitted as a separate variable and we get a separate coefficient.

```{r}
summary(basic_model)$coef
summary(basic_model)$coef[,1]
```

These coefficients are little bit hard to interpret as they are now. Linear regression's coefficients are expressed in the units of the target variable. They represent average increase/decrease of the target given 1 unit change in the input variable.

On the other hand, GLM uses a link function - which is a transformation, to be able to use linear combination of predictors to estimate non-linear target. This transformation is not applied on the target but on the linear combination of predictors. 

We defined the target distribution as `statmod::tweedie(var.power = 1.5, link.power = 0)` and used `link.power=0` which represents logarithmic link function. Now that we know the link function, we can use the inverse link function (exponential function in our case) to obtain more interpretable coefficients.

While the coefficients don't signify the average increase or decrease, their interpretation is even better. The intercept gets translated to average target (similar to linear regression intercept), but the variable coefficients get translated into average multipliers - signifying how much riskier a category is than the average.

```{r}
weighted.mean(dt_pol_w_claims$Burning_Cost, dt_pol_w_claims$Time_Exposure)

summary(basic_model)$coef[,1] %>% 
  exp() %>%
  round(3)
```

As you can see, the CAR category is gone, this is because the most populated category gets designated as the baseline category, which is included within intercept.

The other coefficients (multipliers) represent how much each vehicle type category is riskier than personal car. For example the MOTORBIKE vehicle type is 46% less risky than the personal CAR. On the other hand the TRUCK category is 64% riskier than the personal CAR.

Did you expect this kind of result or are you surprised? Don't forget the riskiness includes not only the aspect of claim loss payments but also how often do these claims occur.
